---
title: "error_dependence_test"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(patchwork)
library(copula)
library(scales)
library(energy)
library(knitr)
library(CopulaSEJ)

source("compare_decoupler_dependence_simulation.R")

data_list_form <- load_data_49()[1:2]


```
For every study we would want to calculate some error metric for each question. Then calculate the dCov between the error metric and the question. 
```{r}
# run_error_dependence_simulation(output_file="output/dcors_df.rds")
#dcors_df = readRDS("output/dcors_df.rds")
dcors_df_rejection = readRDS(decoupler_test_output_file_name(
  reject_experts=T,# F,
  rejection_threshold=0.05,
  #date="2025-05-22",
  date=Sys.Date(),
  rel_dev=TRUE
))

dcors_df_noRej = readRDS(decoupler_test_output_file_name(
  reject_experts=F,# F,
  #date="2025-05-22",
  date=Sys.Date(),
  rel_dev=TRUE
))

stopifnot(nrow(dcors_df_rejection) == nrow(dcors_df_noRej))
dcors_df_noRej$rejection=FALSE
dcors_df_rejection$rejection=TRUE
dcors_df <- rbind(dcors_df_noRej, dcors_df_rejection)

#dcors_df$name = paste0(dcors_df$m, ":", dcors_df$decoupler)
dcors_df$name = paste0(dcors_df$decoupler)
#dcors_df$T_stat = purrr::map_dbl(dcors_df$dcor_T_test, \(x) if (identical(x, NA)) NA else  x$statistic)
```
```{r}
y25 = qnorm(0.25)
y50 = qnorm(0.5)
y75 = qnorm(0.75)

normal_stats <- data.frame(
  x = "Standard Normal",
  y0 = y25 - 1.5 * (y75 - y25),
  y25 = y25,
  y50 = y50,
  y75 = y75,
  y100 = y75 + 1.5 * (y75 - y25)
)
# Assymptotic R^* dependence
get_assymptotic_dependency_plot <- function(df) {
  df$nu = df$nr_questions * (df$nr_questions - 3)/2
  df$approx_normal = sqrt(df$nu-1) * df$dcorT_Q

  df |> filter(!is.na(approx_normal)) |> 
  ggplot(aes(x=name, y=approx_normal, fill=rejection)) + geom_boxplot()  + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
   geom_boxplot(
   aes(x=x, ymin = y0, lower = y25, middle = 0, upper = y75, ymax = y100),
   data=normal_stats,
   stat = "identity",
   inherit.aes = FALSE
 ) + labs(x=NULL, y =parse(text="sqrt(nu-1)(paste(R,'*'))")) +
       scale_fill_discrete(name="Rejection", labels=c("No", "Yes")) 
}


assymptotic_p <- get_assymptotic_dependency_plot(dcors_df)
#assymptotic_p <- get_assymptotic_dependency_plot(dcors_df_noRej)
#assymptotic_rejection_p <- get_assymptotic_dependency_plot(dcors_df_rejection)
approx_normal_filename <- "approx_normal_dependency.png"
ggsave(glue::glue("output/{approx_normal_filename}"), assymptotic_p, width=10, height=5)
assymptotic_p
```

```{r}

nr_not_na = dcors_df |> group_by(name) |> summarize(nr_na=is.na(dcorT_Q) %>% sum(), nr_not_na = (!is.na(dcorT_Q)) %>% sum())

# |> map_if(\(x) x$estimate)
p <- dcors_df |> ggplot(aes(x=name, y=dcorT_Q)) + geom_boxplot()  + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + xlab(NULL)  + theme(plot.margin = margin(20, 10, 10, 20)) 
# save plot

# add the number of studies with not na values as text label
p <- p + geom_text(data=nr_not_na, aes(x=name, y=1.1, label=nr_not_na), vjust=0, hjust=0.4) +  coord_cartesian(ylim = c(-0.5, 0.99), clip = 'off') 

ggsave("Output/dcor_corrected.png", p, width=10, height=5)
p
```
```{r}
extract_summarizing_function <- Vectorize(function(name_str) {
  # write a vectorized version of below
  if (str_starts(name_str, "median")) {
    summarising_func = "Md"
  } else if (str_starts(name_str, "three quantiles")) {
    summarising_func = "3Q"
  } else if (str_starts(name_str, "mean(global)")) {
    summarising_func = "MeG"
  }
  else {
    stop("Name must start with median or 3 quantiles")
  }
  return(summarising_func)
})

extract_error_metric <- function(name_str) {
  error_metric = str_extract(name_str, ":(.*)")
  # remove and
  return(str_remove(error_metric, "and "))
}

nr_studies = length(unique(dcors_df$study_id))
create_dependency_rejection_table <- function(df) {
  a = df |> filter(!is.na(p_value_Q)) |> mutate(dcor_T_p_value = p_value_Q)
  
  # a = a |> mutate("Summarizing function" = extract_summarizing_function(name), "Error metric" =extract_error_metric(name)) |> 
  #   group_by(study_id, `Summarizing function`) |> mutate("Best in study"=if_else(dcorT == min(dcorT), T,F)) |> ungroup()
  a = a  |> group_by(study_id) |> #, D, D_tilde) |> 
    mutate("Best in study"=if_else(dcor_T_p_value == max(dcor_T_p_value), T,F)) |> ungroup()
  
  # for each name get the percentage of p values less than 0.05
  table = a |> filter(!is.nan(dcor_T_p_value)) |> group_by(decoupler) |> summarize(
      D=unique(D_tilde),
    "H_0 Rejected (% of studies)" = paste(round(mean(dcor_T_p_value < 0.05)*100), "%", sep=""),
   `Highest p value (% of studies)`=str_glue("{round(100*sum(`Best in study`)/nr_studies, digits=0)}%"),
   #D=unique(D),
   avg_nr_experts_rejected = round(mean(nr_experts_rejected), digits=1)
   )
  
  # sort table
  table #= table |> arrange(desc(D), desc(D_tilde))
  
}
# do separate for each D value
table_1D_rej = create_dependency_rejection_table(dcors_df_rejection |> filter(D_tilde==1))
table_3D_rej = create_dependency_rejection_table(dcors_df_rejection |> filter(D_tilde==3))
table_1D_No_rej = create_dependency_rejection_table(dcors_df_noRej |> filter(D_tilde==1))
table_3D_No_rej = create_dependency_rejection_table(dcors_df_noRej  |> filter(D_tilde==3))
# save_to_csv_files
table_rej = dplyr::bind_rows(table_3D_rej, table_1D_rej)
table_no_rej = dplyr::bind_rows(table_3D_No_rej, table_1D_No_rej)
table_rej |> readr::write_csv("output/dcor_rejection.csv")
table_no_rej |> readr::write_csv("output/dcor_no_rejection.csv")
# get the t test p values for the corrected dcor
# print as latex table
table_latex = table |> kable("latex", format.args = list(digits=2))
```

