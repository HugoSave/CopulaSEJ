---
title: "presentation_of_support_problem"
output: html_document
---

```{r}
#library(CopulaSEJ)
library(mixtools)
devtools::load_all("../")
source("dev_utils.R")
studies <- load_data_49_filtered(relative_dev_folder = TRUE)
studies <- load_data_49(relative_dev_folder = TRUE)
k_percentiles <- c(5,50,95)
summ_fun <- get_three_quantiles_summarizing_function()$f
```
# Example partioning metric

```{r}
study <- studies[[45]]
test_question_id <- 10
test_set <- study |> filter(question_id == test_question_id)
training_set <- study |> filter(question_id != test_question_id)
test_m_matrix <- test_set |> study_df_single_question_to_summary_matrix(summ_fun, k_percentiles)
training_assessments <- training_set |> study_df_to_summary_array(summ_fun, k_percentiles)
cdf_metric <- get_CDF_decoupler(scale="linear", support_restriction = NULL)

```
```{r}
res <- fit_and_construct_posterior_indep(
        training_assessments,
        training_set |> study_df_to_realizations(),
        test_m_matrix,
        cdf_metric,
        "indep",
        vine_fit_settings = list(eta=10),
        error_estimation_settings = list(out_of_boundary="clamp", method="beta_MAP", prior_std=0.1),
        #error_estimation_settings = list(out_of_boundary="clamp", method="beta_MLE"),
        #error_estimation_settings = list(out_of_boundary="clamp", method="uniform", bw=1),
        q_support_restriction = NULL,
        connection_threshold =  NULL,
        connection_metric="kendall"
      )
```

```{r}
x <- seq(res$posterior$support[1], res$posterior$support[2], length.out = 1000)
y <- res$posterior$logDM(x)
plot(x,exp(y))
s <- sample_log_unnormalized_density(res$posterior$logDM, res$posterior$support, 10000)
median(s)
```
```{r}
f <- approxfun(x, exp(y), yleft=0, yright=0)
area <- integrate(f, res$posterior$support[1], res$posterior$support[2], subdivisions = 10^15)
f_normalized <- function(x) f(x) / area$value
cumulative_probability <- function(x) integrate(f_normalized, res$posterior$support[1], x, subdivisions = 10000)$value

uniroot(\(x) cumulative_probability(x) - 0.5, interval=res$posterior$support)$root
# find median of the posterior
```
```{r}
dists <- linear_distribution_interpolation_matrix_w_overshoot(test_m_matrix, c(0.05,0.5,0.95))
prior_sample_experts_mixtures <- function(n, expert_beliefs) {
  # sample from the dists
  samples <- purrr::map(expert_beliefs, \(x) x$sample(n))
  # return a single vector of samples
  unlist(samples)
}
```

```{r}
bayesian_setup <- BayesianTools::createBayesianSetup(res$posterior$logDM, lower=res$posterior$support[1], upper=res$posterior$support[2])
# bayesian_setup <- BayesianTools::createBayesianSetup(res$posterior$logDM, prior=logunif_prior)
# 
# middle_support = (res$posterior$support[1] + res$posterior$support[2]) / 2
# start_values <- runif(1000, min=res$posterior$support[1], max=res$posterior$support[2]) 
# # log linearly spaced values
# start_values <- exp(seq(log(res$posterior$support[1]), log(res$posterior$support[2]), length.out = 200))
# 
# start_values <- get_starting_values(res$posterior$support, N=10, max_width_for_uniform = 1000)
# Z <- get_starting_values(res$posterior$support, N=1000, max_width_for_uniform = 1000)
start_values <- prior_sample_experts_mixtures(10, dists)
Z <- prior_sample_experts_mixtures(50, dists)

bay_settings <- list(iterations=10000, Z=matrix(Z, nrow=length(Z), ncol=1), startValue=matrix(start_values, nrow=length(start_values), ncol=1)) # (support[1]+support[2])/2)
#bay_settings <- list(iterations=10000, burnin=1000, startValue=4)
#bay_settings <- list(iterations=5000, burnin=1000) # (support[1]+support[2])/2)
bayesian_tools_samples <- BayesianTools::runMCMC(bayesian_setup, sampler="DEzs", settings=bay_settings)
s2_alt <- BayesianTools::getSample(bayesian_tools_samples)[,1]
s2 <- bayesian_tools_samples$Z
```
```{r}
summary(s2_alt)
```
```{r}
summary(s2)
```

```{r}
median(s2_alt)
quantile(s2, 0.0)
mean(s2)
median(s)
plot(density(s))
```

```{r}
res$decoupler_margins |> plot_distributions("pdf")
```





# Examnple CDF independence metric
```{r}
study <- filter_study_keep_ids(studies, 43)[[1]]
study <- change_small_value_in_study_list(list(study), k_percentiles_to_colname(k_percentiles), min_value=0.01)$study_list[[1]]

test_question_id <- 10
test_set <- study |> filter(question_id == test_question_id)
training_set <- study |> filter(question_id != test_question_id)
test_m_matrix <- test_set |> study_df_single_question_to_summary_matrix(summ_fun, k_percentiles)
training_assessments <- training_set |> study_df_to_summary_array(summ_fun, k_percentiles)
cdf_metric <- get_CDF_decoupler(scale="linear", support_restriction = NULL)


```
```{r}
res <- fit_and_construct_posterior_indep(
        training_assessments,
        training_set |> study_df_to_realizations(),
        test_m_matrix,
        cdf_metric,
        "vine",
        vine_fit_settings = list(),
        error_estimation_settings = list(out_of_boundary="clamp", method="kde", bw=1),
        q_support_restriction = NULL
      )

decoupler_margins <- res$decoupler_margins |> 
   purrr::map(\(x) {
  #x$d = switch(x$d, "1" = "M5", "2" = "M50", "3" = "M95"); 
  x$expert_id = paste0("E", x$expert_id);
  x })

res$errors |> plot_3d_errors()  |> plot_add_supports(decoupler_margins)

```
```{r}
obs <- res$flattened_errors[,6]
fit <- ks::kde.boundary(x=obs, xmin=0, xmax=1, boundary.kernel="beta")
f<- approxfun(fit$eval.points, fit$estimate, yleft=0, yright=0)
cdf<-integrate(f, min(fit$eval.points), 0.5)
plot(fit)
```

```{r}
decoupler_margins[6] |> plot_distributions("pdf")
```

```{r}
margin <- decoupler_margins[[6]]
x <- seq(margin$support[1], margin$support[2], length.out = 1000)
y <- margin$pdf(x)
integrate(margin$pdf, margin$support[1], margin$support[2], subdivisions = 10000)
```

```{r}
decoupler_margins[[6]]$pdf(0.4)
```
```{r}
test_set_ext <- add_0_and_100_percentiles(test_set, k_percentiles)
distributions <- interpolate_distributions(test_set_ext, interpolation = "linear")
distributions |> plot_distributions("pdf", fix_range = c(0,300))
```


```{r}
support <- res$posterior$support
log_posterior <- res$posterior$logDM
x = seq(support[1], support[2], length.out = 1000)
y = exp(log_posterior(x))
plot(x, y, type = "l", main = "log posterior")
```
```{r}
integrate(function(x) exp(log_posterior(x)), support[1], 100, subdivisions = 10000)
```
```{r}
samples <- sample_log_unnormalized_density(
  log_posterior,
  support,
  10000
)
```
```{r}
median(samples)
sd(samples)
```

```{r}


```




# Example 1 : Ratio error
```{r}
study <- filter_study_keep_ids(studies, 5)[[1]]
test_question_id <- 1
test_set <- study |> filter(question_id == test_question_id)
training_set <- study |> filter(question_id != test_question_id)
test_m_matrix <- test_set |> study_df_single_question_to_summary_matrix(summ_fun, k_percentiles)
training_assessments <- training_set |> study_df_to_summary_array(summ_fun, k_percentiles)
ratio_metric <- get_ratio_error_metric()
```
```{r}
res <- fit_and_construct_posterior(
        training_assessments,
        training_set |> study_df_to_realizations(),
        test_m_matrix,
        "vine",
        ratio_metric,
        vine_fit_settings = list(),
        error_estimation_settings = list(out_of_boundary="clamp"),
        q_not_cross_zero = TRUE
      )
print(glue::glue("Desired support: {paste0(res$posterior$support, collapse=',')}"))

expert_id <- 3
decoupler_margins <- res$decoupler_margins |> purrr::map(\(x) {
  x$d = switch(x$d, "1" = "M5", "2" = "M50", "3" = "M95"); 
  x$expert_id = paste0("E", x$expert_id);
  x })
exp_error_margins <- decoupler_margins |> purrr::keep(\(x) x$expert_id == paste0("E", expert_id))
  
exp_error_margins |> plot_supports()
```
```{r}
test_m_matrix
```
```{r}
test_m_matrix[,2] |> median()
```

```{r}
decoupler_margins |> plot_supports()
```
```{r}
decoupler_margins |> plot_supports() + xlim(0, 10000)
```
```{r}
res$errors[,,, drop=FALSE] |> plot_3d_errors()
```
```{r}
res$errors[,expert_id,3, drop=FALSE] |> plot_3d_errors()
```

```{r}
# 
error_margins_exp <- res$decoupler_margins |> purrr::keep(\(x) x$expert_id == expert_id && x$d==3) 
error_margins_exp |> plot_distributions("pdf", overshoot = 0)
```
And zoomed in between 0 and 100:
```{r}
error_margins_exp |> plot_distributions("pdf", fix_range=c(0,100)) 
```
It kinda follows the observed error data shown before.

So we get almost 0 for a large section of the support. Here numerical problems happen so for example
while the pdf is non-zero for the whole support. 
```{r}
print(glue::glue("pdf(1000) = {error_margins_exp[[1]]$pdf(1000)}\n
                 cdf(1000) = {error_margins_exp[[1]]$cdf(1000)}\n
                 cdf(1000) == 1 = {error_margins_exp[[1]]$cdf(1000)==1}"))
```

```{r}
q_marginals <- calculate_marginal_posteriors(res$decoupler_margins, test_m_matrix, ratio_metric)
q_marginals_f <- combine_lists_of_functions_to_function(q_marginals)
exp_q_margins <- q_marginals  |> purrr::keep(\(x) x$expert_id == expert_id)
exp_q_margins[3] |> plot_distributions("pdf")
```
We want to have support for q aorund 1 and lower but this margin gives 0 cdf value for values under 1.
 Then the error is above 1500.

```{r}
exp_q_margins[[3]]$cdf(1)
```

That would not generally be a problem, as long as we have some section of the posterior
with valid support. The problem however is that it turns out that there is always one
of the expert whose 

```{r}
a <- res$posterior$logDM(1:10000)
a
any(is.finite(a))
```

```{r}
q_marginals |> plot_distributions("pdf") + xlim(20,50)
```
What about if we look at close to the median? There surely the pdf should be non-zero
```{r}
q_marginals_f$cdfs(45)
q_marginals_f$cdfs(45) |> rvinecopulib::dvinecop(res$error_copula)

```



# Example 2 : Linear error 
```{r}
study <- filter_study_keep_ids(studies, 45)[[1]]
test_question_id <- 11
test_set <- study |> filter(question_id == test_question_id)
training_set <- study |> filter(question_id != test_question_id)
summ_fun = get_median_summarizing_function()
#summ_fun = get_three_quantiles_summarizing_function()
test_m_matrix <- test_set |> study_df_single_question_to_summary_matrix(summ_fun$f, k_percentiles)
training_assessments <- training_set |> study_df_to_summary_array( summ_fun$f, k_percentiles)
#error_metric <- get_linear_error_metric()
error_metric <- get_linear_decoupler()
#error_metric <- get_CDF_decoupler()

p <- default_simulation_params(copula_model = "indep", prediction_method = "copula",
                              error_metric =  get_linear_decoupler(), summarizing_function = get_median_summarizing_function(),
                q_support_restriction = 'non_negative'
              )

res <- fit_and_construct_posterior_indep(
        training_assessments,
        training_set |> study_df_to_realizations(),
        test_m_matrix,
        error_metric,
        "vine",
        vine_fit_settings = list(threshold = 0.7, family_set=c("gaussian", "indep")),
        error_estimation_settings = list(),
        q_support_restriction = "non_negative"
      )
```


```{r}
x <- seq(res$posterior$support[1], res$posterior$support[2], length.out = 1000)
y <- res$posterior$logDM(x)
plot(x,exp(y))
```



```{r}
expert_id <- 7
decoupler_margins <- res$decoupler_margins |> purrr::map(\(x) {
  x$d = switch(x$d, "1" = "M5", "2" = "M50", "3" = "M95"); 
  x$expert_id = paste0("E", x$expert_id);
  x })
exp_error_margins <- decoupler_margins |> purrr::keep(\(x) x$expert_id == paste0("E", expert_id))
  
exp_error_margins |> plot_supports()
```

```{r}
error_margins |> plot_supports()
```

```{r}
res$errors[,expert_id,, drop=FALSE] |> plot_3d_errors()
```
```{r}
res$errors[,expert_id,, drop=FALSE] |> 
  plot_3d_errors()  |> plot_add_supports(exp_error_margins) + xlim(-1,2)
```

```{r}

```
```{r}
```


```{r}
samples <- sample_log_unnormalized_density(res$posterior$logDM, res$posterior$support, 1000)
```
```{r}
median(samples)
```
```{r}
plot(density(samples))
```




